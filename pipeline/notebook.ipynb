{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0aa6d8f-f4f9-471d-ad43-38b10f7b5e8f",
   "metadata": {},
   "source": [
    "# General Information\n",
    "The task of this script is to get data from the web and populate our database\n",
    "\n",
    "So we have nyc taxi data and we clean it here (it is already very clean, but we define the column types). \n",
    "After cleaning we want to load it into the database, but here we have more than 1.3 million entries and\n",
    "it is not possible or smart to push 1.3 million entries into the db at once\n",
    "\n",
    "So I have to chunk the data when I read it so that an iterator is passed to me by pandas.\n",
    "Then I can move over that iterator (chunk by chunk) and push each chunk into the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b7aa4b7-740e-4604-8141-595ac9ed2c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         1  2021-01-01 00:30:10   2021-01-01 00:36:12                1   \n",
      "1         1  2021-01-01 00:51:20   2021-01-01 00:52:19                1   \n",
      "2         1  2021-01-01 00:43:30   2021-01-01 01:11:06                1   \n",
      "3         1  2021-01-01 00:15:48   2021-01-01 00:31:01                0   \n",
      "4         2  2021-01-01 00:31:49   2021-01-01 00:48:21                1   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           2.10           1                  N           142            43   \n",
      "1           0.20           1                  N           238           151   \n",
      "2          14.70           1                  N           132           165   \n",
      "3          10.60           1                  N           138           132   \n",
      "4           4.94           1                  N            68            33   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             2          8.0    3.0      0.5        0.00           0.0   \n",
      "1             2          3.0    0.5      0.5        0.00           0.0   \n",
      "2             1         42.0    0.5      0.5        8.65           0.0   \n",
      "3             1         29.0    0.5      0.5        6.05           0.0   \n",
      "4             1         16.5    0.5      0.5        4.06           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  \n",
      "0                    0.3         11.80                   2.5  \n",
      "1                    0.3          4.30                   0.0  \n",
      "2                    0.3         51.95                   0.0  \n",
      "3                    0.3         36.35                   0.0  \n",
      "4                    0.3         24.36                   2.5  \n",
      "-------------\n",
      "VendorID                          Int64\n",
      "tpep_pickup_datetime     datetime64[ns]\n",
      "tpep_dropoff_datetime    datetime64[ns]\n",
      "passenger_count                   Int64\n",
      "trip_distance                   float64\n",
      "RatecodeID                        Int64\n",
      "store_and_fwd_flag       string[python]\n",
      "PULocationID                      Int64\n",
      "DOLocationID                      Int64\n",
      "payment_type                      Int64\n",
      "fare_amount                     float64\n",
      "extra                           float64\n",
      "mta_tax                         float64\n",
      "tip_amount                      float64\n",
      "tolls_amount                    float64\n",
      "improvement_surcharge           float64\n",
      "total_amount                    float64\n",
      "congestion_surcharge            float64\n",
      "dtype: object\n",
      "-------------\n",
      "(1369765, 18)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# read data from the github repo\n",
    "prefix = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/'\n",
    "filename = 'yellow_tripdata_2021-01.csv.gz'\n",
    "url = prefix + filename\n",
    "\n",
    "# df = pd.read_csv(prefix + 'yellow_tripdata_2021-01.csv.gz') # there was a nrows=100 here, but I want to get all the data\n",
    "# pandas can read a gzipped file easily, so no unzipping needs to be performed\n",
    "\n",
    "dtypes = {\n",
    "    \"VendorID\": \"Int64\",\n",
    "    \"passenger_count\": \"Int64\",\n",
    "    \"trip_distance\": \"float64\",\n",
    "    \"RatecodeID\": \"Int64\",\n",
    "    \"store_and_fwd_flag\": \"string\",\n",
    "    \"PULocationID\": \"Int64\",\n",
    "    \"DOLocationID\": \"Int64\",\n",
    "    \"payment_type\": \"Int64\",\n",
    "    \"fare_amount\": \"float64\",\n",
    "    \"extra\": \"float64\",\n",
    "    \"mta_tax\": \"float64\",\n",
    "    \"tip_amount\": \"float64\",\n",
    "    \"tolls_amount\": \"float64\",\n",
    "    \"improvement_surcharge\": \"float64\",\n",
    "    \"total_amount\": \"float64\",\n",
    "    \"congestion_surcharge\": \"float64\"\n",
    "}\n",
    "\n",
    "parse_dates = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"]\n",
    "\n",
    "df = pd.read_csv(url, dtype = dtypes, parse_dates = parse_dates)\n",
    "\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "print(\"-------------\")\n",
    "print(df.dtypes)\n",
    "print(\"-------------\")\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2615861-0503-4049-85fb-2543c0e4032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"postgresql://root:root@localhost:5432/ny_taxi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8fa956-4544-4c59-87d5-de4371e3604d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(0).to_sql(name=\"yellow_taxi_data\", con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5502caa-e4e7-447e-9c62-fc0de31050fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name=\"yellow_taxi_data\", con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef31a4bd-0bdd-407a-89f5-4ffca96a7a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv(url, dtype = dtypes, parse_dates = parse_dates, iterator=True, chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d5ed72a-1498-4c23-b498-8f34ceb4627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8000a1e1-f074-4c25-803e-1fc3c4df1c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4ff93f89954258b029290552ad6e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created\n",
      "inserted: 100000\n",
      "inserted: 100000\n",
      "inserted: 100000\n",
      "inserted: 100000\n",
      "inserted: 100000\n",
      "inserted: 100000\n",
      "inserted: 100000\n",
      "inserted: 100000\n",
      "inserted: 100000\n",
      "inserted: 100000\n",
      "inserted: 100000\n",
      "inserted: 100000\n",
      "inserted: 100000\n",
      "inserted: 69765\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# add each chunk individually to the db now\n",
    "first = True   \n",
    "for chunk in tqdm(df_iter):\n",
    "    if first:\n",
    "        chunk.head(0).to_sql(name=\"yellow_taxi_data\", con=engine, if_exists=\"replace\")\n",
    "        first = False\n",
    "        print(\"Table created\")\n",
    "    \n",
    "    chunk.to_sql(name=\"yellow_taxi_data\", con=engine, if_exists=\"append\", chunksize=2000)\n",
    "    print(\"inserted: {0}\".format(len(chunk)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daae806a-3889-4ec2-97ba-e519dc073577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
